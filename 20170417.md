### 我咨询了一下嘉琪大神的看法。 

- 如果要***用HLS实现TensorFlow***很难，写成C很复杂。用ARM搭载Linus控制+FPGA跑加速还不错。如果只有FPGA（titan的板子）的话，最好烧一个ARM核跑控制，其他部分跑加速。
就算是写成C，TensorFlow也不好实现。

> 或许只能尝试其他思路了，比如说直接根据搭好的框架写芯片。

- 关于图像识别，如果是***普通的图像识别***网上已经有开源的VGG16的框架+参数（500M+）可以直接跑。但是对于***车牌*** 或者***人脸识别***会比较复杂：一是需要先进行物体定位，而是不仅需要普通的物体识别还需要特征识别（似乎没有现成的参数代码，需要自己钻研）。

> 我觉得我们可以先实现物体识别用VGG16或者Alexnet。再研究人脸或者车牌识别。最后研究物体定位。

- 物体识别主要用***CNN***，物体定位应该也是用CNN，但是自动驾驶的决策部分还需要RNN等时序上的学习+强化学习。（构架多种网络）

- 关于TensorFlow，嘉琪大神给的意见是tensorboard她没用过，感觉比较复杂而且数据比较奇怪。我认为如果太过复杂就不用了，可以先学习一下。

- 我提了一下用pynqz1的板子做cnn的可能性，她说可能性不大，而且pynqz1不一定好用。

> 不过我觉得可以试试，是不是可以找老王买一块板啊，学术价999
> 
> 毕竟用Python的代码量少好多。但是不知道底层代码有多少。。

- 之前我有说过cnn是先计算再***反向学习***的。虽然是这样没错，不过我之前没有了解反向学习需要进行***梯度计算***（微分之类的等）狠狠狠复杂（嘉琪大神原话）。把这学习参数的这部分用FPGA做狠狠狠复杂。
> 所以酌情考虑，我们可以先不实现反向学习的部分在FPGA上。还是先在CPU或者GPU上跑参数吧。。

### 个人总结：
 
- 我才知道TensorFlow在win上很弱没有更新。。所以这周四方便帮忙装一下**Ubuntu**么~~~万分感谢~~~需要我准备什么东西么？？

> 另外集成电路设计大赛真的就是玩玩（才有深切感受），只有FPGA的titan板想要短期实现基于深度学习的物体识别，应该还是烧个SYSTEM进去才是正道。

> 好好搞大学生项目才是正道。

- 针对自动驾驶的各个部分我们还需要调研其理论架构等：**物体识别**、**物体定位**、**驾驶决策**等等（我还不太了解，这是我目前觉得可以深入了解的三个方向）。

> 其中物体识别（CNN，不涉及时间）分为车牌/人脸识别（难，没有现成代码或者参数）、普通物体识别（有现成代码和参数）。
> 
> 物体定位（应该也有一些针对性的网络，但是也是CNN的范畴-不涉及时间）
> 
> 驾驶决策（不仅需要CNN还需要RNN等时序相关网络-涉及时间上的决策-可能需要搭建混合NN网络）


- 用TensorFlow实现物体识别、物体定位、驾驶决策（C还是C++还是Python？）：时间允许的话，我倾向用Python全部实现一遍，再移植。因为据说底层还挺复杂的。

> 先实现普通物体识别，再实现车牌或者人脸识别；
> 
> 物体定位是另外一方面（还未过多考察，可能要与物体识别结合）；
> 
> 驾驶决策等等更加复杂了得到后期了。


- **训练集**：针对不同的应用选择不同的训练集。

> 普通物体识别：我推荐ImageNet有名的图像识别集（其他的应用我还没找到比较合适的，这是接下来的工作的一部分）
> 
> 人脸；
> 
> 车牌；
> 
> 物体定位（这个我记得有一些训练集来着）；
> 
> 驾驶决策（这个太泛泛了，不好找暂时可以不找训练集）


- 关于***在板上搭载linus系统***：
	- 我听说zedboard还是zynq上就有linus系统的TF卡，可以直接读取，很方便啊，可以找粟涛、王军、王自鑫谁都可以要个板玩，没板啥都干不了。
	- 如果没有现成的linus，就在ARM上搭一个（有现成代码/模型，可以请教张希斌组/我好像打错名字了∠）。
	- 实在不行就学习在FPGA上搭一个linus或者ARM+Linus（应该不会这么惨）。


- 学习使用ARM（要用到**SDK**？你们有没有安装？球安装包）。


- 明天开会讨论怎么把ARM和FPGA结合在一起，我觉得我们可以先看点资料。

- 最后一点：还需要doc么？
